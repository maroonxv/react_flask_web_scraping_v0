
from abc import ABC, abstractmethod
from datetime import datetime
from src.shared.domain.events import DomainEvent

class BaseEventHandler(ABC):
    """
    äº‹ä»¶å¤„ç†å™¨åŸºç±»
    æä¾›é€šç”¨çš„äº‹ä»¶æ ¼å¼åŒ–æ–¹æ³•
    """
    
    @abstractmethod
    def handle(self, event: DomainEvent) -> None:
        """
        å¤„ç†äº‹ä»¶ï¼ˆå­ç±»å¿…é¡»å®ç°ï¼‰
        
        å‚æ•°:
            event: DomainEvent å®ä¾‹
        """
        pass
    
    def _format_event_to_log(self, event: DomainEvent) -> dict:
        """
        å°†é¢†åŸŸäº‹ä»¶è½¬æ¢ä¸ºæ—¥å¿—æ ¼å¼ï¼ˆé€šç”¨æ–¹æ³•ï¼‰
        
        å‚æ•°:
            event: DomainEventå®ä¾‹
            
        è¿”å›:
            æ ¼å¼åŒ–çš„æ—¥å¿—å­—å…¸
        """
        # æ ¹æ®äº‹ä»¶ç±»å‹ç”Ÿæˆäººç±»å¯è¯»çš„æ¶ˆæ¯
        message, level = self._get_message_and_level(event)
        
        return {
            "timestamp": self._format_timestamp(event.timestamp),
            "level": level,
            "message": message,
            "event_type": event.event_type,
            "task_id": event.task_id,
            "data": event.data
        }
    
    def _get_message_and_level(self, event: DomainEvent) -> tuple[str, str]:
        """
        æ ¹æ®äº‹ä»¶ç±»å‹ç”Ÿæˆæ¶ˆæ¯å’Œæ—¥å¿—çº§åˆ«
        
        è¿”å›:
            (message, level) å…ƒç»„
        """
        event_type = event.event_type
        data = event.data
        
        # --- ä»»åŠ¡ç”Ÿå‘½å‘¨æœŸäº‹ä»¶ (Task Life Cycle) ---
        if event_type == "TaskCreatedEvent":
            return (
                f"â–¶ ä»»åŠ¡åˆ›å»º: {data.get('start_url', 'N/A')} "
                f"[ç­–ç•¥: {data.get('strategy', 'BFS')}, æœ€å¤§æ·±åº¦: {data.get('max_depth', 3)}]",
                "INFO"
            )
        
        elif event_type == "TaskStartedEvent" or event_type == "CRAWL_STARTED":
             return (
                f"â–¶ ä»»åŠ¡å¼€å§‹", 
                "INFO"
            )
        
        elif event_type == "TaskPausedEvent" or event_type == "CRAWL_PAUSED":
            return (
                f"â¸ ä»»åŠ¡å·²æš‚åœ",
                "WARNING"
            )
            
        elif event_type == "TaskResumedEvent" or event_type == "CRAWL_RESUMED":
            return (
                f"â–¶ ä»»åŠ¡å·²æ¢å¤",
                "INFO"
            )
            
        elif event_type == "TaskCompletedEvent" or event_type == "CRAWL_COMPLETED":
            total_pages = data.get('total_pages', 0)
            total_pdfs = data.get('total_pdfs', 0)
            elapsed_time = data.get('elapsed_time', 0)
            return (
                f"âœ“ çˆ¬å–å®Œæˆ! å…±çˆ¬å– {total_pages} ä¸ªé¡µé¢, "
                f"å‘ç° {total_pdfs} ä¸ªPDF "
                f"(è€—æ—¶: {elapsed_time:.1f}ç§’)",
                "SUCCESS"
            )
        
        elif event_type == "TaskFailedEvent" or event_type == "CRAWL_STOPPED":
             # æ³¨æ„ï¼šCRAWL_STOPPED åœ¨æ—§é€»è¾‘ä¸­æ˜¯ Warningï¼ŒTaskFailed æ˜¯ Error
             if event_type == "TaskFailedEvent":
                 return (f"âœ— ä»»åŠ¡å¤±è´¥: {data.get('error_message', 'æœªçŸ¥é”™è¯¯')}", "ERROR")
             return (f"â¹ ä»»åŠ¡å·²åœæ­¢", "WARNING")

        # --- çˆ¬å–è¿‡ç¨‹äº‹ä»¶ (Crawl Process) ---
        
        elif event_type == "PageCrawledEvent" or event_type == "PAGE_CRAWLED":
            title = data.get('title', 'æ— æ ‡é¢˜')
            url = data.get('url', '')
            depth = data.get('depth', 0)
            pdf_count = data.get('pdf_count', 0)
            
            pdf_info = f", å‘ç°{pdf_count}ä¸ªPDF" if pdf_count > 0 else ""
            return (
                f"âœ“ çˆ¬å–æˆåŠŸ: {title} (æ·±åº¦: {depth}{pdf_info})\n  URL: {url}",
                "INFO"
            )
        
        elif event_type == "PdfFoundEvent" or event_type == "PDF_FOUND":
            pdf_urls = data.get('pdf_urls', [])
            source_page = data.get('source_page_url', data.get('source_page', ''))
            count = data.get('count', 0)
            
            # åªæ˜¾ç¤ºå‰3ä¸ªPDFçš„æ–‡ä»¶å
            pdf_names = [url.split('/')[-1] for url in pdf_urls[:3]]
            more = f" (+{count - 3}ä¸ªæ›´å¤š)" if count > 3 else ""
            
            return (
                f"ğŸ“„ å‘ç° {count} ä¸ªPDF: {', '.join(pdf_names)}{more}\n"
                f"  æ¥æº: {source_page}",
                "SUCCESS"
            )
        
        elif event_type == "CrawlErrorEvent" or event_type == "CRAWL_ERROR":
            url = data.get('url', '')
            error_type = data.get('error_type', 'UNKNOWN')
            error_message = data.get('error_message', '')
            
            return (
                f"âœ— çˆ¬å–å¤±è´¥ [{error_type}]: {url}\n"
                f"  é”™è¯¯: {error_message}",
                "ERROR"
            )
        
        elif event_type == "LinkFilteredEvent":
            return (
                f"âˆ… é“¾æ¥è¿‡æ»¤: {data.get('url')} ({data.get('reason')})",
                "DEBUG"
            )
            
        else:
            # æœªçŸ¥äº‹ä»¶ç±»å‹
            return (
                f"äº‹ä»¶: {event_type}",
                "DEBUG"
            )
    
    def _format_timestamp(self, timestamp: datetime) -> str:
        """æ ¼å¼åŒ–æ—¶é—´æˆ³"""
        if not isinstance(timestamp, datetime):
             return str(timestamp)
        return timestamp.strftime('%Y-%m-%d %H:%M:%S')
