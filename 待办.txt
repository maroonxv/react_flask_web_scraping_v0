正在开发事件处理机制，待办包括：
1. 完善 EventBus 
2. 完善 BaseEventHandler
3. 完善基于事件处理机制的日志系统，包括两部分：
    a. 将日志记录到日志文件中的 logging_handler
    b. 将日志发往浏览器前端的 websocket_handler
4. 在 test/unit 中撰写针对上述所有组件的单元测试
5. 在 test/integration 中撰写融入了事件和日志机制的爬虫系统


完善日志系统，提供这五种日志：
1. 【任务生命周期日志】(Task Lifecycle)
   - 任务启动/停止/暂停/恢复
   - 任务配置（起始URL、深度、策略）
   - 任务完成统计（总URL数、成功率、耗时）
   
2. 【URL处理日志】(URL Processing)  
   - URL入队/出队
   - URL去重命中/未命中
   - Robots协议检查结果
   - HTTP请求与响应（状态码、耗时）
   
3. 【数据提取日志】(Data Extraction) 
   - PDF链接提取（成功/失败、数量）
   - 元数据提取（标题、作者等字段的提取情况）
   - 数据验证结果（字段缺失、格式错误）
   
4. 【错误与异常日志】(Errors & Exceptions) 
   - 网络异常（超时、连接失败、DNS错误）
   - 解析失败（HTML解析错误、编码问题）
   - 数据保存失败
   
5. 【性能与监控日志】(Performance & Monitoring) 
   - 速率控制触发情况（请求延迟、限流）
   - 队列状态（待爬取URL数量、队列深度）

这个项目采用领域驱动设计的原则进行设计开发。
我已经把这个项目的领域层和基础设施层都写好了，现在正在开发应用层。请你：
1. 检查中CrawlerService对于领域层和基础设施层的调用是否正确
2. CrawlerService作为应用层，将领域事件发布到总线上   
3. 在CrawlerService中增加一个查询某个CrawlTask最新results的方法
   然后在_execute_crawl_loop的每一轮循环中，每当results增加一条结果，
   就查询一次（供crawler_view调用）
   